{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow-hub opencv-python matplotlib pandas shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optional if you are using a GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add a center poinit\n",
    "# --------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "def get_angle(line1, line2):\n",
    "    d1 = (line1[1][0] - line1[0][0], line1[1][1] - line1[0][1])\n",
    "    d2 = (line2[1][0] - line2[0][0], line2[1][1] - line2[0][1])\n",
    "    p = d1[0] * d2[0] + d1[1] * d2[1]\n",
    "    n1 = math.sqrt(d1[0] * d1[0] + d1[1] * d1[1])\n",
    "    n2 = math.sqrt(d2[0] * d2[0] + d2[1] * d2[1])\n",
    "    ang = math.acos(p / (n1 * n2))\n",
    "    ang = math.degrees(ang)\n",
    "    return ang\n",
    "def get_intersections(line1, line2):\n",
    "    A = np.array(line1)\n",
    "    B = np.array(line2)\n",
    "    t, s = np.linalg.solve(np.array([A[1]-A[0], B[0]-B[1]]).T, B[0]-A[0])    \n",
    "    \n",
    "    return (1-t)*A[0] + t*A[1]\n",
    "def getPerspectiveTransformMatrix(vid_path , show_frame = False):\n",
    "\n",
    "    cap = cv2.VideoCapture(vid_path)\n",
    "    # width , height = 1080 , 720\n",
    "    border = np.zeros((720,1280,3), np.uint8)\n",
    "    # print(\"Start\")\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    test_frame =np.copy(frame)\n",
    "\n",
    "    h, w = frame.shape[:2]\n",
    "    mask = np.zeros([h+2, w+2], np.uint8) \n",
    "    # bgr\n",
    "    diff_value = (3,1,3)\n",
    "    black = (0,0,0)\n",
    "    frame = cv2.GaussianBlur(frame , (7,7) , 0)\n",
    "\n",
    "    fillpoints = [(100,0) , (100,700) , (300,350) , (1000,350) , (1200,700)]\n",
    "    \n",
    "    for point in fillpoints:\n",
    "        cv2.floodFill(frame, mask, point, black, diff_value, diff_value)\n",
    "    for point in fillpoints:\n",
    "        cv2.circle(frame , point , 5 ,(0,0,255) , -1)\n",
    "\n",
    "    # 灰階\n",
    "    imgray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    # 二值化\n",
    "    ret,thresh = cv2.threshold(imgray,100,255,0)\n",
    "    # 找輪廓\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    contours = list(contours)\n",
    "    # 根據輪廓面積大小進行sort\n",
    "    contours.sort(key = cv2.contourArea , reverse=True)\n",
    "    # 畫出最大的輪廓\n",
    "    cv2.drawContours(border, contours[0:1], -1, (0,0,255), 10)\n",
    "\n",
    "\n",
    "\n",
    "    # 灰階\n",
    "    imgray = cv2.cvtColor(border,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    canny = cv2.Canny(imgray, 30, 100)\n",
    "    lines = cv2.HoughLinesP(canny , 1.0 , np.pi/180 , 100 , np.array([]) , 200 , 100)\n",
    "\n",
    "    cv2.line(frame,(100,100),(100,500),(255,255,255),5)\n",
    "\n",
    "    horizon_line = []\n",
    "    left_vertical_line = None\n",
    "    right_vertical_line = None\n",
    "\n",
    "    try:\n",
    "    # 畫球場的垂直線 和 找到水平線座標\n",
    "        for line in lines:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                line_angle = get_angle([(x1,y1),(x2,y2)] , [(0,0),(0,100)])\n",
    "                line_angle_90 = 180 - line_angle if line_angle > 90 else line_angle\n",
    "                vectorx = x2 - x1\n",
    "                vectory = y2 - y1\n",
    "                \n",
    "                if  (line_angle_90 < 40 and int(line_angle)): \n",
    "\n",
    "                    if left_vertical_line == None and line_angle > 90:\n",
    "                        # left_vertical_line = [(x1 - 20 , y1) , (x2 -20, y2)]\n",
    "                        left_vertical_line = [(x1 , y1) , (x2, y2)]\n",
    "                        cv2.line(frame,(x1 - vectorx * 100, y1 - vectory * 100),(x1 + vectorx * 100,y1 + vectory * 100),(255,0,0),5)\n",
    "                    elif right_vertical_line == None and line_angle < 90:\n",
    "                        right_vertical_line = [(x1, y1) , (x2, y2)]\n",
    "                        cv2.line(frame,(x1 - vectorx * 100, y1 - vectory * 100),(x1 + vectorx * 100,y1 + vectory * 100),(255,0,0),5)\n",
    "\n",
    "                elif line_angle_90 > 85:\n",
    "\n",
    "                    horizon_line.append([[x1 ,y1] , [x2,y2] ])\n",
    "\n",
    "        # 畫上下兩條水平線\n",
    "        top_line = min(horizon_line , key = lambda x : x[0][1] + x[1][1])\n",
    "        # top_line[0][1] -= 20\n",
    "        # top_line[1][1] -= 20\n",
    "        x1 , y1 = top_line[0]\n",
    "        x2 , y2 = top_line[1]\n",
    "        cv2.line(frame,(x1 - (x2-x1) * 100, y1 - (y2-y1) * 100),(x1 + (x2-x1) * 100,y1 + (y2-y1) * 100),(255,0,0),5)    \n",
    "        bottom_line = max(horizon_line , key = lambda x : x[0][1] + x[1][1])\n",
    "        # print(bottom_line)\n",
    "        x1 , y1 = bottom_line[0]\n",
    "        x2 , y2 = bottom_line[1]\n",
    "        cv2.line(frame,(x1 - (x2-x1) * 100, y1 - (y2-y1) * 100),(x1 + (x2-x1) * 100,y1 + (y2-y1) * 100),(255,0,0),5)    \n",
    "\n",
    "        # print(get_intersections(top_line , vertical_line[0]).astype(int))\n",
    "        corner = []\n",
    "        corner.append(get_intersections(top_line , left_vertical_line).astype(int))\n",
    "        corner.append(get_intersections(bottom_line , left_vertical_line).astype(int))\n",
    "        corner.append(get_intersections(bottom_line , right_vertical_line).astype(int))\n",
    "        corner.append(get_intersections(top_line , right_vertical_line).astype(int))\n",
    "        cv2.circle(frame , get_intersections(top_line , left_vertical_line).astype(int) , 5 , (0,255,0),-1)\n",
    "        cv2.circle(frame , get_intersections(top_line , right_vertical_line).astype(int) , 5 , (0,255,0),-1)\n",
    "        cv2.circle(frame , get_intersections(bottom_line , left_vertical_line).astype(int) , 5 , (0,255,0),-1)\n",
    "        cv2.circle(frame , get_intersections(bottom_line , right_vertical_line).astype(int) , 5 , (0,255,0),-1)\n",
    "        \n",
    "    except:\n",
    "        return -1 , -1 , -1, -1\n",
    "        \n",
    "\n",
    "    # cv2.imshow('board' , border)          \n",
    "            \n",
    "    # 進行透視變換\n",
    "    old = np.float32(corner)\n",
    "    new = np.float32([[0,0], [0,h-1], [w-1,h-1] , [w-1,0] ])\n",
    "    matrix = cv2.getPerspectiveTransform(old , new)\n",
    "    imgOutput = cv2.warpPerspective(test_frame, matrix, (w , h), cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=(0,0,0))\n",
    "\n",
    "    \n",
    "    if show_frame:\n",
    "        cv2.imshow('thresh' , thresh)     \n",
    "        cv2.imshow('board' , border)  \n",
    "        cv2.imshow('frame' , frame)\n",
    "        cv2.imshow('Perspective', imgOutput)\n",
    "\n",
    "        while cv2.waitKey(1) == -1:\n",
    "            pass\n",
    "    # cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "    # Center point\n",
    "    corner = np.array(corner)\n",
    "    centerX = int(corner[:,0].mean())\n",
    "    centerY = int(corner[:,1].mean())\n",
    "    ratio = ((corner[1][1]-corner[0][1]+corner[2][1]-corner[3][1])/2)/(corner[2][0]-corner[1][0])\n",
    "    tranY = int(centerY - ratio*115)\n",
    "    center  = (centerX, tranY)\n",
    "    \n",
    "\n",
    "    return matrix , corner, center , 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = hub.load('https://tfhub.dev/google/movenet/multipose/lightning/1')\n",
    "movenet = model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Draw People"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def draw_keypoints(frame, shaped, confidence_threshold, color):\n",
    "    for kp in shaped:\n",
    "        ky, kx = kp\n",
    "        cv2.circle(frame, (int(kx), int(ky)), 4, color, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EDGES = {\n",
    "    (0, 1): 'm',\n",
    "    (0, 2): 'c',\n",
    "    (1, 3): 'm',\n",
    "    (2, 4): 'c',\n",
    "    (0, 5): 'm',\n",
    "    (0, 6): 'c',\n",
    "    (5, 7): 'm',\n",
    "    (7, 9): 'm',\n",
    "    (6, 8): 'c',\n",
    "    (8, 10): 'c',\n",
    "    (5, 6): 'y',\n",
    "    (5, 11): 'm',\n",
    "    (6, 12): 'c',\n",
    "    (11, 12): 'y',\n",
    "    (11, 13): 'm',\n",
    "    (13, 15): 'm',\n",
    "    (12, 14): 'c',\n",
    "    (14, 16): 'c'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def draw_connections(frame, shaped, edges, confidence_threshold):\n",
    "    for edge, color in edges.items():\n",
    "        p1, p2 = edge\n",
    "        y1, x1 = shaped[p1]\n",
    "        y2, x2 = shaped[p2]\n",
    "        cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,int(y2)), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to loop through each person detected and render\n",
    "def loop_through_people(frame, keypoints_with_scores, edges, confidence_threshold):\n",
    "    i=126\n",
    "    for person in keypoints_with_scores:\n",
    "        draw_connections(frame, person, edges, confidence_threshold)\n",
    "        draw_keypoints(frame, person, confidence_threshold, (0,i,0))\n",
    "        i=255\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Make Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FILE_RES=\"/Users/sunny/Desktop/ai_badminton/part1/train/\"  # 原影片的資料夾\n",
    "FILE_DST=\"/Users/sunny/move_dataset/\" # 要存 move_data 資料夾\n",
    "CONFIDENCE_THRESHOLD = 0.1 # 判斷點的信心分數大於 CONFIDENCE_THRESHOLD\n",
    "MIN_CONFIDENCE_NUM = 14 # 17個點至少要有 MIN_CONFIDENCE_NUM 的點大於 CONFIDENCE_THRESHOLD 才會拿 movnet預測的資料，否則拿前一幀的資料\n",
    "SAVE_DATA = False # 要不要存檔案\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# detection and save A B all move data\n",
    "\n",
    "for num in tqdm(range(472,801)):\n",
    "    \n",
    "    file_name = '%05d' % num\n",
    "    df = pd.read_csv(f\"{FILE_RES}{file_name}/{file_name}_S2.csv\")\n",
    "    cap = cv2.VideoCapture(f'{FILE_RES}{file_name}/{file_name}.mp4')\n",
    "    matrix, corner, center, _ = getPerspectiveTransformMatrix(f'{FILE_RES}{file_name}/{file_name}.mp4')\n",
    "    \n",
    "    if center == -1:\n",
    "        continue\n",
    "        \n",
    "    hitframe = 1\n",
    "    index = 0\n",
    "\n",
    "    y, x = 720, 1280\n",
    "\n",
    "    A_player = []\n",
    "    B_player = []\n",
    "    A_label = []\n",
    "    B_label = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "\n",
    "        if frame is None:\n",
    "            break\n",
    "\n",
    "        # Resize image\n",
    "        img = frame.copy()\n",
    "        img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 352,640)\n",
    "        input_img = tf.cast(img, dtype=tf.int32)\n",
    "\n",
    "\n",
    "        # Detection section\n",
    "        results = movenet(input_img)\n",
    "        keypoints_with_scores = results['output_0'].numpy()[:,:,:51].reshape((6,17,3))\n",
    "\n",
    "        \n",
    "        # Find the players\n",
    "        for person in keypoints_with_scores:\n",
    "            # y x\n",
    "            shaped = np.squeeze(np.multiply(person, [y,x,1]))\n",
    "            point = Point(shaped[16][1], shaped[16][0])\n",
    "            polygon = Polygon(corner)\n",
    "\n",
    "            if polygon.contains(point):\n",
    "\n",
    "                if point.y > center[1] and (np.count_nonzero(shaped[:,2]>= CONFIDENCE_THRESHOLD)) > MIN_CONFIDENCE_NUM:\n",
    "                    B_prev = shaped\n",
    "\n",
    "                elif point.y <= center[1] and (np.count_nonzero(shaped[:,2] >= CONFIDENCE_THRESHOLD)) > MIN_CONFIDENCE_NUM:\n",
    "                    A_prev = shaped\n",
    "\n",
    "        A_player.append(A_prev)\n",
    "        B_player.append(B_prev)\n",
    "        \n",
    "        \n",
    "        if index < len(df):\n",
    "            if hitframe == df.iloc[index]['HitFrame']-2 or hitframe == df.iloc[index]['HitFrame']-1 or hitframe == df.iloc[index]['HitFrame'] or hitframe == df.iloc[index]['HitFrame']+1 or hitframe == df.iloc[index]['HitFrame']+2:\n",
    "                if df.iloc[index]['Hitter'] == 'A':\n",
    "                    A_label.append(1)\n",
    "                    B_label.append(0)\n",
    "                else: \n",
    "                    A_label.append(0)\n",
    "                    B_label.append(1)\n",
    "                    \n",
    "                if hitframe == df.iloc[index]['HitFrame']+2:\n",
    "                    index+=1\n",
    "            else:\n",
    "                A_label.append(0)\n",
    "                B_label.append(0)\n",
    "        else:\n",
    "            A_label.append(0)\n",
    "            B_label.append(0)\n",
    "            \n",
    "    \n",
    "        # Show the image\n",
    "        \n",
    "        # loop_through_people(frame, target, EDGES, 0.1)\n",
    "        # print(\"draw\")\n",
    "        \n",
    "        #A\n",
    "        draw_connections(frame, A_prev[:,:2], EDGES, 0.1)\n",
    "        draw_keypoints(frame, A_prev[:,:2], 0.1, (0,128,0))\n",
    "        #B\n",
    "        draw_connections(frame, B_prev[:,:2], EDGES, 0.1)\n",
    "        draw_keypoints(frame, B_prev[:,:2], 0.1, (0,255,0))\n",
    "\n",
    "        cv2.circle(frame , center, 5 , (0,0,0),-1)\n",
    "        cv2.circle(frame , corner[0], 5 , (0,0,0),-1)\n",
    "        cv2.circle(frame , corner[1], 5 , (0,0,0),-1)\n",
    "        cv2.circle(frame , corner[2], 5 , (0,0,0),-1)\n",
    "        cv2.circle(frame , corner[3], 5 , (0,0,0),-1)\n",
    "        cv2.imshow('Movenet Multipose', frame)        \n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "            break\n",
    "            \n",
    "        hitframe += 1\n",
    "            \n",
    "    \n",
    "    # Save data\n",
    "    if SAVE_DATA:\n",
    "        np.save(f'{FILE_DST}{file_name}_A_move', A_player)\n",
    "        np.save(f'{FILE_DST}{file_name}_B_move', B_player)\n",
    "        np.save(f'{FILE_DST}{file_name}_A_hit_label', A_label)\n",
    "        np.save(f'{FILE_DST}{file_name}_B_hit_label', B_label)\n",
    "    \n",
    "    # print(hitframe)\n",
    "cap.release()\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# show A B all move data\n",
    "\n",
    "for num in tqdm(range(1,801)):\n",
    "    \n",
    "    file_name = '%05d' % num\n",
    "    \n",
    "    if not os.path.exists(f'{FILE_DST}{file_name}_A_move.npy'):\n",
    "        continue\n",
    "    \n",
    "    cap = cv2.VideoCapture(f'{FILE_RES}{file_name}/{file_name}.mp4')\n",
    "    A_player = np.load(f'{FILE_DST}{file_name}_A_move.npy')\n",
    "    B_player = np.load(f'{FILE_DST}{file_name}_B_move.npy')\n",
    "        \n",
    "    hitframe = 0\n",
    "    index = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "\n",
    "        if frame is None:\n",
    "            break\n",
    "\n",
    "    \n",
    "        # Show the image\n",
    "        \n",
    "        # A\n",
    "        draw_connections(frame, A_player[hitframe][:,:2], EDGES, 0.1)\n",
    "        draw_keypoints(frame, A_player[hitframe][:,:2], 0.1, (0,128,0))\n",
    "        \n",
    "        # B\n",
    "        draw_connections(frame, B_player[hitframe][:,:2], EDGES, 0.1)\n",
    "        draw_keypoints(frame, B_player[hitframe][:,:2], 0.1, (0,255,0))\n",
    "       \n",
    "        cv2.imshow('Movenet Multipose', frame)        \n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "            break\n",
    "            \n",
    "        hitframe += 1\n",
    "        \n",
    "    # print(hitframe)\n",
    "    \n",
    "cap.release()    \n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test\n",
    "# train_A = np.load(f'/Users/sunny/move_dataset/{file_name}_A_move.npy')\n",
    "# train_B = np.load(f'/Users/sunny/move_dataset/{file_name}_B_move.npy')\n",
    "# label_A = np.load(f'/Users/sunny/move_dataset/{file_name}_A_hit_label.npy')\n",
    "# label_B = np.load(f'/Users/sunny/move_dataset/{file_name}_B_hit_label.npy')\n",
    "# print(label_A[:40])\n",
    "# print(label_B[:40])\n",
    "\n",
    "# print((train_A == A_player).all())\n",
    "# print((train_B == B_player).all())\n",
    "# print((label_A == A_label).all())\n",
    "# print((label_B == B_label).all())\n",
    "\n",
    "# print(np.array(A_player).shape)\n",
    "# print(np.array(B_player).shape)\n",
    "\n",
    "# print(A_label[100:140])\n",
    "# print(B_label[100:140])\n",
    "\n",
    "# Homography\n",
    "# pts_src = np.array([[141, 131], [480, 159], [493, 630],[64, 601]])\n",
    "# pts_dst = np.array([[0, 0],[256, 0],[256, 256],[0, 256]])\n",
    "# h, status = cv2.findHomography(pts_src, pts_dst)\n",
    "# im_out = cv2.warpPerspective(im_src, h, (im_dst.shape[1],im_dst.shape[0]))\n",
    "\n",
    "# load data\n",
    "\n",
    "# for num in tqdm(range(1,801)):\n",
    "#     # print(num)\n",
    "#     file_name = '%05d' % num\n",
    "#     if not os.path.exists(f'{FILE_DST}{file_name}{file_name}_A_move.npy'):\n",
    "#         continue\n",
    "        \n",
    "#     A_player = np.load(f'{FILE_DST}{file_name}_A_move.npy')\n",
    "#     B_player = np.load(f'{FILE_DST}{file_name}_B_move.npy')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
